# Stable Quadrature Schemes

## Composite Quadratures

When dealing with functions $f$ that may lack smoothness, it can be advantageous to divide the integration interval $[a,b]$ into $m$ smaller, equally sized subintervals $\{[x_{i-1},x_i]\}_{i=1}^m$. Each subinterval has a length of $h:=(b-a)/m$. Within each subinterval, we apply a low-degree interpolatory quadrature formula.

For example, using the trapezium rule on $[x_{i-1},x_i]$, we find

$$
\begin{align}
   \mathcal{C}_{1,m}(f) &= \frac{b-a}m\, \Bigl[ \Bigl( \frac{1}{2} f(x_0) + \frac{1}{2} f(x_1) \Bigr)
   + \Bigl(\frac{1}{2} f(x_1) + \frac{1}{2} f(x_2) \Bigr) + \cdots
   + \Bigl( \frac{1}{2} f(x_{m-1}) + \frac{1}{2} f(x_m) \Bigr) \Bigr] \notag\\
   &= h \Bigl[ \frac{1}{2} f(x_0) + \sum_{i=1}^{m-1} f(x_i) + \frac{1}{2} f(x_m) \Bigr].
\end{align}
$$

This scheme involves $m+1$ evaluations of $f$. To use Simpson's rule, we introduce an additional midpoint node $x_{i-1/2}:=(x_{i-1}+x_i)/2$ in each subinterval. The composite Simpson's rule is then given by:

$$
\begin{align}
   \mathcal{C}_{2,m}(f) &= \frac{b-a}{m} \, \Bigl[ \frac{1}{6} f(x_0) + \frac{2}{3} f(x_{1/2}) + \frac{1}{6} f(x_1)
   + \frac{1}{6} f(x_1) + \frac{2}{3} f(x_{3/2}) + \frac{1}{6} f(x_2)\\
   & \phantom{= \frac{b-a}{m} \, \Bigl[} + \cdots + \frac{1}{6} f(x_{m-1}) + \frac{2}{3} f(x_{m-1/2}) + \frac{1}{6} f(x_m)\Bigr]\\
   &= \frac{h}{6} \Bigl[ f(x_0) + 4 \sum_{i=1}^{m} f(x_{i-1/2}) + 2 \sum_{i=1}^{m-1} f(x_i) + f(x_m) \Bigr].
\end{align}
$$

It involves $2m+1$ evaluations of $f$.

Error bounds for these methods can be obtained directly from those of the underlying methods. For $\mathcal{C}_{1,m}$ we have, in the subinterval $[x_{i-1},x_i]$,

$$
\Bigl| \int_{x_{i-1}}^{x_i} f(x) dx - \tfrac{h}{2} (f(x_{i-1}) + f(x_i)) \Bigr| \le \frac{1}{2!}\,\max_{\xi\in[x_{i-1},x_i]}\,|f''(\xi)| \,\int_{x_{i-1}}^{x_i} |\omega_2(x)| dx = \frac{h^3}{12}\,\max_{\xi\in[x_{i-1},x_i]}\,|f''(\xi)|,
$$

where $\omega_2(x)=(x-x_{i-1})(x-x_i)$. Adding these up, we have in $[a,b]=[x_0,x_m]$,

$$
\bigl|\mathcal{I}(f)-\mathcal{C}_{1,m}(f)\bigr| \le \frac{mh^3}{12}\,\max_i\Bigl\{\max_{\xi\in[x_{i-1},x_i]}\,|f''(\xi)|\Bigr\} \leq (b-a)\,\frac{h^2}{12}\,\max_{\xi\in[a,b]}\,|f''(\xi)|.
$$

## Gaussian Quadratures

The degree of exactness of an interpolatory quadrature $\mathcal{Q}_n$ is at least $n$. By considering $\omega_{n+1}^2(x)=(x-x_0)^2\cdots(x-x_n)^2 \in \mathcal{P}_{2n+2}$, we find that the degree of exactness of any interpolatory quadrature cannot be equal to or larger than $2n+2$. Gauss showed that by judicious choice of the nodes $\{x_k\}$, one can indeed obtain a quadrature exact for all $f \in \mathcal{P}_{2n+1}$. The resulting Gaussian quadrature rests on the following:

```{prf:theorem} Gaussian quadrature
The interpolatory quadrature formula $\mathcal{Q}_n$ achieves a degree of exactness $2n+1$ if and only if its nodes $x_0, \ldots, x_n$ are such that the polynomial

$$
\omega_{n+1}(x) = \prod_{i=0}^n (x - x_i),
$$

meets the condition $\int_a^b \omega_{n+1}(x) \, p(x) \, dx = 0$ for all $p \in \mathcal{P}_n$.
```

Thus, the nodes $\{x_k\}_{k=0}^n$ are chosen so that the error polynomial $\omega_{n+1} \in \mathcal{P}_{n+1}$ is in the orthogonal complement relative to the $(n+1)$-dimensional space $\mathcal{P}_n$ within the $(n+2)$-dimensional space $\mathcal{P}_{n+1}$ with respect to the inner product $\langle p, q \rangle = \int_a^b p(x) \, q(x) \, dx$. A proof of the theorem is given in the optional materials section.

```{prf:definition}
An interpolatory quadrature method with $n+1$ nodes that achieves a degree of exactness $2n+1$ is termed a *Gaussian quadrature method*. 
```

In short,

$$
\mathcal{Q}_n \text{ Gaussian} \qquad \Leftrightarrow \qquad \langle \omega_{n+1}, p \rangle = 0 \quad \forall \, p \in \mathcal{P}_n.
$$

Once the nodes are determined, the coefficients can be computed as usual. Gaussian quadrature weights are always positive, unlike the coefficients $\sigma_k$ of a general quadrature formula. This can be illustrated by considering

$$
L_k^2(x) = \prod_{i = 0 \atop i \neq k}^n \frac{(x-x_i)^2}{(x_k-x_j)^2} \in \mathcal{P}_{2n}.
$$

With the degree of exactness of  $2n+1$ and $L_k^2(x_j) = \delta_{jk}$, we find that:

$$
0 < \mathcal{I}(L_k^2) = \mathcal{Q}_n(L_k^2) = \sigma_k.
$$

In summary, Gaussian quadrature combines two crucial properties: stability and speed of convergence.

While we only scratch the surface of Gaussian quadrature, its close relationship to orthogonal polynomials makes it a fascinating topic for further study, e.g. see {cite}`SuliMayers` and {cite}`Plato` for more details.

## Python skills

### Composite Newton-Cotes quadrature rules

Scipy provides an implementation of the composite trapezium and Simpson's rules, Numpy only has the former.

```python
import numpy as np
from scipy import integrate

# Define a function to integrate
def my_function(x):
    return x ** 2

# Define the interval
a = 0  # Lower limit
b = 1  # Upper limit
n = 100  # Number of sample points

# Generate sample points
x = np.linspace(a, b, n)
y = my_function(x)

# Trapezoidal Rule
trapz_result_np = np.trapz(y, x)
trapz_result_scipy = integrate.trapz(y, x)

# Simpson's Rule
simps_result = integrate.simps(y, x)

# Display the results
print("Trapezoidal Rule (numpy):", trapz_result_np)
print("Trapezoidal Rule (scipy):", trapz_result_scipy)
print("Simpson's Rule:", simps_result)
```

### Gaussian quadrature

The code below compares exact integration with SciPy's Gaussian quadrature implementation `integrate.quad`, which uses an adaptive composite formula  (based partly on Gaussâ€“Kronrod quadrature). In addition, the Gaussian quadrature function `integrate.fixed_quad` with a specified number of quadrature points is evaluated.

```python
import scipy.integrate as integrate

# Define a function to integrate and its exact integral
def my_function(x):
    p = 9
    return x**p

def integral_of_my_function(a,b):
    p = 9
    return (b**(p+1) - a**(p+1)) / (p+1)

# Define the interval
a = 1  # Lower limit
b = 5  # Upper limit

# Using exact integration formula
result_exact = integral_of_my_function(a,b)
print("Exact integration:", result_exact)

# Using scipy.integrate.quad, which uses an (adaptive) composite Gaussian quadrature
result_quad, _ = integrate.quad(my_function, a, b)
print("Gaussian Quadrature (scipy.integrate.quad):", result_quad)

# Using scipy.integrate.fixed_quad with different orders
for n in [2, 3, 4, 5]:  # Different number of quadrature points
    result_fixed_quad, _ = integrate.fixed_quad(my_function, a, b, n=n)
    print(f"Gaussian Quadrature of order {n} (fixed_quad):", result_fixed_quad)
```

## Self-check questions

```{admonition} **Question**
:class: tip
Show, for $f \in C^3[a,b]$,

$$
\bigl|\mathcal{I}(f)-\mathcal{C}_{2,m}(f)\bigr| \le (b-a)\,\frac{h^3}{192}\,\max_{\xi\in[a,b]}\,|f'''(\xi)|.
$$
```

````{dropdown} **Answer**
Using

$$
\int_{x_{i-1}}^{x_i} |\omega_3(x)| dx = h^4 \int_0^1 \bigl|(t-0)(t-1/2)(t-1)\bigr| dt = \frac{h^4}{32},
$$

we find

$$
\bigl|\mathcal{I}(f)-\mathcal{C}_{2,m}(f)\bigr| \le \frac{m}{3!}\,\frac{h^4}{32}\,\max_{\xi\in[a,b]}\,|f'''(\xi)| = (b-a)\,\frac{h^3}{192}\,\max_{\xi\in[a,b]}\,|f'''(\xi)|.
$$

```{note}
When $f$ is smooth enough, we could actually prove with a more sophisticated argument taking the symmetry of the nodes into account that

$$
\bigl|\mathcal{I}(f)-\mathcal{C}_{2,m}(f)\bigr| = (b-a)\,\frac{h^4}{2880}\,\max_{\xi\in[a,b]}\,|f^{(4)}(\xi)|.
$$
```
````

```{admonition} **Question**
:class: tip
Let $f(x) = \exp(-x^2)$. We wish to compare several methods to approximate

$$
\mathcal{I}(f) := \int_0^1 f(x) dx
$$

where only *three* evaluations of $f$ are allowed.

Writing your formulas clearly, compute approximations to $\mathcal{I}(f)$ using the:

1. rectangle rule, i.e. composite quadrature with $n=0$ and $m=3$;
2. trapezium rule, i.e. composite quadrature with $n=1$ and $m=2$;
3. closed Newton-Cotes with $n=2$.

Compare with the exact answer $\mathcal{I}(f) = (\sqrt\pi/2)\,\textrm{erf}\,1=0.746824132812\cdots$.
```

```{dropdown} **Answer**
1. rectangle rule:
   
   $$
   \mathcal{C}_{0,3}(f) = \frac{1}{3}\bigl[ f(\frac{1}{6}) + f(\frac{1}{2}) + f(\frac{5}{6}) \bigr] = 0.7502523\cdots
   $$

2. trapezium rule:
   
   $$
   \mathcal{C}_{1,2}(f) = \frac{1}{2}\bigl[\frac{1}{2} f(0) + f(\frac{1}{2}) + \frac{1}{2} f(1)\bigr] = 0.73137025\cdots
   $$

3. closed Newton-Cotes with $n=2$:
   
   $$
   \mathcal{Q}_2(f) = \frac{1}{6} f(0) + \frac{2}{3} f(\frac{1}{2}) + \frac{1}{6} f(1) = 0.7471804289\cdots
   $$
   
Comparing with the exact answer $\mathcal{I}(f)=0.746824132812\cdots$, the closed Newton-Cotes with $n=2$ gives the best result.
```

```{admonition} **Question**
:class: tip
Let $[a,b] = [-1,1]$.

1. Given the nodes $\{t_k\}=\bigl\{1/2,\bigl(1\pm\sqrt{3/5}\bigr)/2\bigr\}$, compute the coefficients $\{\sigma_k\}$ of the interpolatory quadrature formula.

2. Use your result to compute the interpolatory quadrature $\mathcal{Q}_2'(f)$ for $f(x)=\exp(-x^2)$ and compare with the results of the methods of the previous question.
```

```{dropdown} **Answer**
1. We compute
   
   $$
   \begin{align*}
   \sigma_0 & = \int_0^1 \frac{t-t_1}{t_0-t_1}\cdot\frac{t-t_2}{t_0-t_2} dt = \frac{5}{18} = 0.2777\cdots\\
   \sigma_2 & = \sigma_0 = \frac{5}{18} = 0.2777\cdots\\
   \sigma_1 & = 1 - (\sigma_0 + \sigma_2) = \frac{4}{9} = 0.4444\cdots.
   \end{align*}
   $$

2. We get
   
   $$
   \mathcal{Q}_2'(f) = \frac{5}{18} f(t_0) + \frac{4}{9} f(t_1) + \frac{5}{18} f(t_2) = 0.74681458419\cdots,
   $$
   
   which is better than any of the results of the previous question.
```

```{admonition} **Question**
:class: tip
Find nodes $\{t_0,t_1\}\subset[0,1]$ and coefficients $\{\sigma_0,\sigma_1\}$ such that the resulting quadrature formula has degree of exactness $3$, i.e.

$$
\sigma_0 f(t_0) + \sigma_1 f(t_1) = \int_0^1 f(t) \>\mathrm{d}t,
$$

for every $f \in \mathcal{P}_3$. Hint: consider polynomials in $t-\frac{1}{2}$ instead of $t$.
```

```{dropdown} **Answer**
Requiring the quadrature formula to be exact for $f(t)=1$, $t-\frac{1}{2}$, $(t-\frac{1}{2})^2$ and $(t-\frac{1}{2})^3$, we have, with $\tau_i := t_i-\frac{1}{2}$,

$$
\begin{align*}
   &\sigma_0 + \sigma_1 = 1\\
   &\sigma_0\tau_0 + \sigma_1\tau_1 = 0\\
   &\sigma_0\tau_0^2 + \sigma_1\tau_1^2 = \frac{1}{12}\\
   &\sigma_0\tau_0^3 + \sigma_1\tau_1^3 = 0.
\end{align*}
$$

Since these relations are all symmetric in $\sigma_0$ and $\sigma_1$, and in $\tau_0$ and $\tau_1$, we look for a solution satisfying

$$
   \sigma_1 = \pm\sigma_0, \qquad \tau_1 = \pm\tau_0.
$$

The first equation implies that $\sigma_1 = \sigma_0 = \frac{1}{2}$. The second then implies that $\tau_1 = -\tau_0$; from the third equation, we find that $\tau_0 = 1/\sqrt{12}$.
```

```{admonition} **Question**
:class: tip
Similarly, find nodes $\{t_0,t_1,t_2\}\subset[0,1]$ and coefficients $\{\sigma_0,\sigma_1,\sigma_2\}$ such that

$$
\sigma_0 f(t_0) + \sigma_1 f(t_1) + \sigma_2 f(t_2) = \int_0^1 f(t) dt
$$

for every $f \in \mathcal{P}_5$. Hint: symmetry!
```

```{dropdown} **Answer**
By symmetry, $t_1=\frac{1}{2}$ and $t_2=1-t_0$, and $\sigma_2=\sigma_0=:\sigma$. Requiring that the quadrature is exact for constant functions, we have $\sigma_1=1-2\sigma$. Taking $f(t)=t^2$ and $f(t)=t^4$ (we do not get any more information
from $t^3$), we get

$$
\begin{align*}
   &\sigma t_0^2 + (1-2\sigma)\frac{1}{4} + \sigma(1-t_0)^2 = \frac{1}{3}
   & &\Rightarrow\qquad \sigma(2t_0-1)^2 = \frac{1}{6}\\
   &\sigma t_0^4 + (1-2\sigma)\frac{1}{16} + \sigma(1-t_0)^4 = \frac{1}{5}
   & &\Rightarrow\qquad \sigma(2t_0-1)^2(4t_0^2-4t_0+7) = \frac{11}{10}\,.
\end{align*}
$$

(It is not surprising that $t_1=\frac{1}{2}$ is a solution of these equations.) Putting these together,

$$
   4t_0^2 - 4t_0 + 7 = \frac{33}{5}
   \qquad\Rightarrow\qquad
   t_0 = \frac12\pm\frac12\sqrt{\frac35}
   \quad\textrm{and}\quad
   \sigma = \frac5{18}\,.
$$
```

```{admonition} **Question**
:class: tip
Decompose the interval $[a,b]$ into $m$ subintervals of equal length $h := (b-a)/m$. Let $\mathcal{C}_{h,1}$ be the composite trapezium rule defined on these subintervals and let $\mathcal{C}_{h,2}$ be the composite Simpson's rule defined on these subintervals (thus for the calculation of $\mathcal{C}_{h,2}(f)$ the function $f$ is evaluated with a step-size of $h/2$). Show that

$$
\mathcal{C}_{h,2}(f) = \frac{4}{3} \mathcal{C}_{h/2,1}(f) - \frac{1}{3} \mathcal{C}_{h,1}(f).
$$

Here $\mathcal{C}_{h/2,1}$ is the trapezium rule with subintervals of the length $h/2$.
```

```{dropdown} **Answer**
Let

$$
x_i = a + i h = a + \frac{i}{m} (b-a), \qquad i = 0, 1, \ldots, m.
$$

We denote the mid-point of the interval $[x_{i-1}, x_i]$ by

$$
x_{i-1/2} := \frac{x_{i-1} + x_i}{2}.
$$

One calculates

$$
\begin{eqnarray*}
\frac{4}{3} \mathcal{C}_{h/2,1}(f) - \frac{1}{3} \mathcal{C}_{h,1}(f) &=& \frac{4}{3} \sum_{i = 1}^m \Bigl(\frac{h}{4} (f(x_{i-1}) + f(x_{i-1/2}))  +  \frac{h}{4} (f(x_{i-1/2}) + f(x_i))\Bigr)\\ 
&& - \frac{1}{3} \sum_{i = 1}^m \Bigl( \frac{h}{2} (f(x_{i-1}) + f(x_i)) \Bigr)\\
&=& \sum_{i = 1}^m \underbrace{\Bigl( \frac{h}{6} (f(x_{i-1}) + \frac{2 h}{3} (f(x_{i-1/2}) + \frac{h}{6} (f(x_{i-1}) \Bigr)}_{\mbox{Simpson's rule on $[x_{i-1}, x_i]$}}\\
&=& \mathcal{C}_{h,2}(f).
\end{eqnarray*}
$$
```

## Optional material

`````{dropdown} Theory of Gaussian quadrature

Gaussian quadrature is an advanced numerical method for evaluating integrals, particularly useful when dealing with functions that are difficult to integrate analytically. The general approach of Gaussian quadrature is based on the concept of weighted integrals, where the integration problem is defined as:

$$
\mathcal{I}(f) := \int_a^b f(x) \, \gamma(x) \, dx, \qquad f \in C[a,b],
$$

where $\gamma(x)$ is a weight function that simplifies the integration process for certain types of functions.

```{admonition} Understanding the role of the weight function $\gamma$
:class: note
1. **Practical Applications**: Often, one encounters integrals of functions $g(x)$ that can be decomposed into a product of a smoothly varying function $f$ and a weight function $\gamma$, such that $g = f \cdot \gamma$. In such cases, a common technique is to approximate $f$ by a polynomial $p$, and then integrate the product $p \cdot \gamma$.

2. **Extension to Unbounded Domains**: When extending this concept to unbounded integration domains, we consider $a = -\infty$ and $b = \infty$. Here, $\gamma$ is chosen to ensure that the product $p \cdot \gamma$ remains integrable for polynomials $p$ of degree $n$.

For initial understanding, consider the simpler case where $\gamma \equiv 1$ and $a, b \in \mathbb{R}$.
```

As before, we consider a quadrature formula of the form

$$
\mathcal{Q}_n(f) = \sum_{k=0}^n \sigma_k f(x_k).
$$

In contrast to Newton-Cotes formulas, Gaussian quadrature benefits from the flexibility of choosing the nodes $x_k$. It is possible to significantly enhance the accuracy of the quadrature formula by optimising the node locations. We aim to achieve a quadrature method with a degree of exactness of $2n + 1$. This is facilitated by the concept of the scalar product:

$$
\langle f,g \rangle = \int_a^b f(x) g(x) \, \gamma(x) \, dx,
$$

This function $\gamma$ is the same as the weight above and assumed to be piecewise continuous, integrable, and positive. Moreover, we assume that $\langle p, p \rangle$ is finite for all $p \in \mathcal{P}_n$. Common examples include $\gamma = 1$ for $a,b \in \mathbb{R}$, $\gamma = 1/t$ for $a=0$, $b=\infty$, and $\gamma = 1/\sqrt{1-t^2}$ for $a=-1$, $b=1$.

Our focus is to demonstrate that the optimal quadrature nodes correspond to the roots of orthogonal polynomials. To understand this, we must explore two key results about orthogonal polynomials.
 
```{prf:theorem} Roots of orthogonal polynomials
For a polynomial $\tilde{p} \in \mathcal{P}_{n+1}$, if

$$
\langle \tilde{p}, p \rangle = 0 \quad \forall \, p \in \mathcal{P}_n,
$$

then $\tilde{p}$ either equals zero or has exactly $n+1$ distinct roots in the open interval $(a,b)$.
```

```{prf:proof}
Suppose $\tilde{p} \neq 0$. If $\tilde{p}$ has roots $\xi_0, \xi_1, \ldots, \xi_\ell$ where its sign changes, then construct a polynomial $s(x) = \prod_{j=0}^\ell (x - \xi_j)$. If no such roots exist, let $s(x) = 1$. The product $\tilde{p} \cdot s$ does not change sign, implying $\langle \tilde{p}, s \rangle \neq 0$. The degree of $s$ is greater than $n$, so $\tilde{p}$ has more than $n$ sign changes. However, as a polynomial in $\mathcal{P}_{n+1}$, $\tilde{p}$ can have at most $n+1$ sign changes.
```

This indicates that the roots of $\tilde{p}$ are ideal candidates for quadrature nodes. However, a question arises: is there a unique polynomial that satisfies this condition? If different polynomials meet the criterion, they could have varying roots, affecting the choice of nodes. The following theorem addresses this concern.

```{prf:theorem} Uniqueness of the orthogonal polynomial
For any two non-zero polynomials $\tilde{p}, \bar{p} \in \mathcal{P}_{n+1}$ satisfying the condition

$$
\langle \tilde{p}, p \rangle = 0 \quad \forall \, p \in \mathcal{P}_n,
$$

there exists a non-zero scalar $\alpha \in \mathbb{R}$ such that $\bar{p} = \alpha \, \tilde{p}$.
```

```{prf:proof}
Consider the polynomial representations of $\tilde{p}(x)$ and $\bar{p}(x)$. The coefficient $\tilde{a}_{n+1}$ must be non-zero; otherwise, $\tilde{p}$ would belong to $\mathcal{P}_n$. Setting $\alpha = \bar{a}_{n+1} / \tilde{a}_{n+1}$, we define $\Delta p = \alpha \tilde{p} - \bar{p}$. This difference falls within $\mathcal{P}_n$, and from our condition, it follows that 

$$
\| \Delta p \|^2 = \langle \Delta p, \Delta p \rangle = \langle \alpha \tilde{p} - \bar{p}, \Delta
p \rangle = \alpha \langle \tilde{p}, \Delta p \rangle - \langle \bar{p}, \Delta p \rangle = 0,
$$ 

implying $\bar{p} = \alpha \, \tilde{p}$.
```

```{prf:example} Orthonormal basis of $\mathcal{P}_2$
Using the Gram-Schmidt method, we construct an orthonormal basis for $\mathcal{P}_2$ with respect to the scalar product:

$$
\langle f,g \rangle = \int_{-1}^1 f(x) \, g(x) \, dx, \qquad \gamma = 1.
$$

The resulting basis functions are:

$$
q_0 = \frac{1}{\sqrt{2}},\quad q_1 = \sqrt{\frac{3}{2}} t,\quad q_2 = \sqrt{\frac{45}{8}} \Bigl(t^2 - \frac{1}{3}\Bigr).
$$

For $k=1$, $q_2$ meets the orthogonality condition, as any polynomial $p \in \mathcal{P}_1$ can be expressed as a linear combination of $q_0$ and $q_1$, leading to $\langle q_2, p \rangle = 0$. The roots of $q_2$ within $(-1,1)$ are $\pm \frac{1}{\sqrt{3}} \approx \pm 0.5774$. Other quadratic polynomials meeting this condition will be of the form $\delta (t^2 - 1/3)$ for some $\delta \in \mathbb{R}$.
```

We now arrive at the central result.
 
```{prf:theorem} Main theorem on Gaussian quadrature
For an integration weight $\gamma$, the interpolatory quadrature formula $\mathcal{Q}_n$ achieves a degree of exactness $2n+1$ with respect to $\gamma$ if and only if its nodes $x_0, \ldots, x_n$ are such that the polynomial

$$
\tilde{p}(x) = \prod_{i=0}^n (x - x_i),
$$

meets the orthogonality condition $\langle \tilde{p}, p \rangle = 0$ for all $p \in \mathcal{P}_n$.
```

```{prf:proof}
a) If $\mathcal{Q}_n$ has a degree of exactness $2n+1$ with respect to $\gamma$, then for all $f = \tilde{p} \cdot p \in \mathcal{P}_{2n+1}$ with $p \in \mathcal{P}_{n}$, it follows that

$$
\int_a^b \tilde{p}(x) \, p(x) \, \gamma(x) \, dx = \mathcal{Q}_n (\tilde{p} \cdot p) = 0,
$$

satisfying the orthogonality condition.

b) Conversely, if the orthogonality condition holds, we show that $\mathcal{Q}_n$ has a degree of exactness $2n +1$. For any $f \in \mathcal{P}_{2n+1}$, polynomial division yields $f = \tilde{p} \cdot p + r$ with $p, r \in \mathcal{P}_n$. Then

$$
\int_a^b f(x) \, \gamma(x) \, dx = \int_a^b \tilde{p}(x) \, p(x) \, \gamma(x) \, dx + \int_a^b r(x) \, \gamma(x) \, dx = 0 + \int_a^b r(x) \, \gamma(x) \, dx.
$$

Similarly, because $\tilde{p}(x_k) = 0$,

$$
\mathcal{Q}_n(f) = \sum_{i=0}^n \sigma_k \bigl( \tilde{p}(x_k) \, p(x_k) + r(x_k) \bigr) = \sum_{i=0}^n \sigma_k r(x_k) = \mathcal{Q}_n(r),
$$

leading to the conclusion that $\mathcal{Q}_n$ integrates $f$ exactly, proving its degree of exactness is $2n+1$.
```

This concludes the theoretical foundation of Gaussian quadrature. Next, we explore its practical implementation.

```{admonition} Task
:class: tip
Given a set number of nodes $n+1$ and a positive, piecewise continuous integration weight $\gamma$, the objective is to find the quadrature formula $\mathcal{Q}_n$ with a degree of exactness $2n + 1$ relative to $\gamma$.
```

To construct $\mathcal{Q}_n$, follow these steps:

1. **Finding the Nodes**: Select a polynomial $\tilde{p}$ satisfying the orthogonality condition. If an orthogonal basis of $\mathcal{P}_{n+1}$ is not known, use the Gram-Schmidt method starting with the basis $\{1, x, x^2, \ldots, x^n, x^{n+1}\}$ of $\mathcal{P}_{n+1}$.
   
2. **Roots of $q_{n+1}$**: Determine the roots of $\tilde{p}$; these are the nodes of $\mathcal{Q}_n$.

3. **Calculating Weights**: Compute the weights of $\mathcal{Q}_n$ using the usual formula for interpolatory quadrature rules, involving the integration of a Lagrange basis polynomial.

```{note} 
Finding roots of $\tilde{p}$ for large $n$ can be challenging. Special techniques for finding roots of orthogonal polynomials, such as recursion relationships, are available but beyond the scope of this discussion. Most literature on Gaussian quadrature delves into these techniques in detail; see {cite}`Plato`.
```
